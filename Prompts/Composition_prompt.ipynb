{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using PipelinePromptTemplate，其实就是一个大模板由几个小模板组成，然后每个小模板里又各自含有自己的参数，实现的步骤如下："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 先写一个总模板：\n",
    "full_template = \"\"\"{introduction} \n",
    "\n",
    "{example} \n",
    "\n",
    "{start}\"\"\" \n",
    "\n",
    "2. 然后再将各个小模板生成，小模板里包含有各自的参数: \n",
    "example_template = \"\"\"Here's an example of an interaction: \n",
    "\n",
    "Q: {example_q} \\\n",
    "A: {example_a}\"\"\" \\\n",
    "\n",
    "example_prompt = PromptTemplate.from_template(example_template) \n",
    "\n",
    "3. 用PipelinePromptTemplate将小模板匹配起来: \\\n",
    "input_prompts = [ \\\n",
    "    (\"introduction\", introduction_prompt), \\\n",
    "    (\"example\", example_prompt), \\\n",
    "    (\"start\", start_prompt) \\\n",
    "] \n",
    "\n",
    "pipeline_prompt = PipelinePromptTemplate(final_prompt=full_prompt,pipeline_prompts=input_prompts) \n",
    "\n",
    "4. 最后，通过format()传入各个参数：\\\n",
    "pipeline_prompt.format( \\\n",
    "    person=\"Elon Musk\", \\\n",
    "    example_q=\"What's your favorite car?\", \\\n",
    "    example_a=\"Telsa\", \\\n",
    "    input=\"What's your favorite social media site?\" \\\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts.pipeline import PipelinePromptTemplate\n",
    "from langchain.prompts.prompt import PromptTemplate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### #先定义一个整体的模板，里面包含三个部分,用来生成finaly prompt：\n",
    "{introduction} \\\n",
    "{example} \\\n",
    "{start} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_template = \"\"\"{introduction}\n",
    "\n",
    "{example}\n",
    "\n",
    "{start}\"\"\"\n",
    "full_prompt = PromptTemplate.from_template(full_template)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### #然后分别定义各个部分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# introduction_template\n",
    "full_template = \"\"\"{introduction}\n",
    "\n",
    "{example}\n",
    "\n",
    "{start}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example_template\n",
    "example_template = \"\"\"Here's an example of an interaction:\n",
    "\n",
    "Q: {example_q}\n",
    "A: {example_a}\"\"\"\n",
    "\n",
    "example_prompt = PromptTemplate.from_template(example_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "start_template = \"\"\"Now, do this for real!\n",
    "\n",
    "Q: {input}\n",
    "A:\"\"\"\n",
    "\n",
    "start_prompt = PromptTemplate.from_template(start_template)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### #然后根据整体模板，生成input_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_prompts = [\n",
    "    (\"introduction\", introduction_prompt),\n",
    "    (\"example\", example_prompt),\n",
    "    (\"start\", start_prompt)\n",
    "]\n",
    "\n",
    "pipeline_prompt = PipelinePromptTemplate(final_prompt=full_prompt,pipeline_prompts=input_prompts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 然后final_prompt和pipeline_prompts传入，生成pipeline_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_prompt = PipelinePromptTemplate(final_prompt=full_prompt, pipeline_prompts=input_prompts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" You are impersonating Elon Musk.\\n\\nHere's an example of an interaction:\\n\\nQ: What's your favorite car?\\nA: Telsa\\n\\nNow, do this for real!\\n\\nQ: What's your favorite social media site?\\nA:\""
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_prompt.format(\n",
    "    person=\"Elon Musk\",\n",
    "    example_q=\"What's your favorite car?\",\n",
    "    example_a=\"Telsa\",\n",
    "    input=\"What's your favorite social media site?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.11 ('openai')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "382edab7741184ad6aa1b3bda453c7375fcc346d80c0b8f027407f5537ace097"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
