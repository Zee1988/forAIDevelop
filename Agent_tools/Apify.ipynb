{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "openai.api_key = os.environ['OPENAI_API_KEY']\n",
    "apify_api_token = os.environ['APIFY_API_TOKEN']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Apify是一个网络抓取和数据提取的云平台，它提供了一个由一千多个现成的应用程序组成的生态系统，这些应用程序被称为Actors，用于各种网络抓取、爬行和数据提取用例。例如，你可以用它来提取谷歌搜索结果、Instagram和Facebook的个人资料、亚马逊或Shopify的产品、谷歌地图的评论等等。\n",
    "#### 在本例中，我们将使用Website Content Crawler Actor，它可以深度抓取文档、知识库、帮助中心或博客等网站，并从网页中提取文本内容。然后我们将文档输入矢量索引，并从中回答问题。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders.base import Document\n",
    "from langchain.indexes import VectorstoreIndexCreator\n",
    "from langchain.utilities import ApifyWrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apify = ApifyWrapper()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 然后运行Actor，等待它完成，并将其结果从Apify数据集获取到LangChain文档加载器中。\n",
    "#### 注意，如果在Apify数据集中已经有一些结果，可以使用ApifyDatasetLoader直接加载它们，如本笔记本所示。在该笔记本中，您还可以找到dataset_mapping_function的解释，该函数用于将字段从Apify数据集记录映射到LangChain Document字段。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = apify.call_actor(\n",
    "    actor_id=\"apify/website-content-crawler\",\n",
    "    run_input={\"startUrls\":[{\"url\": \"https://python.langchain.com/en/latest/\"}]},\n",
    "    dataset_mapping_function= lambda item: Document(\n",
    "        page_content=item['text'] or \"\", metadata={\"source\": item[\"url\"]}\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the vector index from the crawled documents:\n",
    "index = VectorstoreIndexCreator().from_loaders([loader])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And finally, query the vector index:\n",
    "query = \"What is LangChain?\"\n",
    "result = index.query_with_sources(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result[\"answer\"])\n",
    "print(result[\"sources\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.11 ('openai')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "382edab7741184ad6aa1b3bda453c7375fcc346d80c0b8f027407f5537ace097"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
