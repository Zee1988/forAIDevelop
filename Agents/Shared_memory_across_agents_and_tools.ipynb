{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "openai.api_key = os.environ['OPENAI_API_KEY']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 下面步骤将创建一个自定义代理。座席可以访问会话内存、搜索工具和摘要工具。并且，摘要工具还需要访问会话内存。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import ZeroShotAgent, Tool, AgentExecutor\n",
    "from langchain.memory import ConversationBufferMemory, ReadOnlySharedMemory\n",
    "from langchain import OpenAI, LLMChain, PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\" This is a conversation between a human and a bot:\n",
    "\n",
    "{chat_history}\n",
    "\n",
    "Write a summary of the conversation for {input}:\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(input_variables=[\"input\", \"chat_history\"], template=template)\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\")\n",
    "readonlymemory = ReadOnlySharedMemory(memory=memory)\n",
    "summry_chain = LLMChain(\n",
    "    llm=OpenAI(),\n",
    "    prompt=prompt,\n",
    "    verbose=True,\n",
    "    memory=readonlymemory, # use the read-only memory to prevent the tool from modifying the memory\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search = GoogleSearchAPIWrapper()\n",
    "tools = [\n",
    "    Tool(\n",
    "        name=\"Search\",\n",
    "        func=search.run,\n",
    "        description=\"useful for when you need to answer questions about current events\",\n",
    "    ),\n",
    "    Tool(\n",
    "        name=\"Summary\",\n",
    "        func=summry_chain.run,\n",
    "        description=\"useful for when you summarize a conversation. The input to this tool should be a string, representing who will read this summary.\",\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = \"\"\"Have a conversation with a human, answering the following questions as best you can. You have access to the following tools:\"\"\"\n",
    "suffix = \"\"\"Begin!\"\n",
    "\n",
    "{chat_history}\n",
    "Question: {input}\n",
    "{agent_scratchpad}\"\"\"\n",
    "\n",
    "prompt = ZeroShotAgent.create_prompt(\n",
    "    tools,\n",
    "    prefix=prefix,\n",
    "    suffix=suffix,\n",
    "    input_variables=[\"input\", \"chat_history\", \"agent_scratchpad\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now construct the LLMChain, with the Memory object, and then create the agent:\n",
    "llm_chain = LLMChain(llm=OpenAI(temperature=0), prompt=prompt)\n",
    "agent = ZeroShotAgent(llm_chain=llm_chain, tools=tools, verbose=True)\n",
    "agent_chain = AgentExecutor.from_agent_and_tools(\n",
    "    agent=agent, tools=tools, verbose=True, memory=memory\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_chain.run(input=\"What is ChatGPT?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_chain.run(input=\"Who developed it?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_chain.run(\n",
    "    input=\"Thanks. Summarize the conversation, for my daughter 5 years old.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(agent_chain.memory.buffer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 为了进行比较，下面是一个为代理和工具使用相同内存的糟糕示例:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This is a bad practice for using the memory.\n",
    "## Use the ReadOnlySharedMemory class, as shown above.\n",
    "\n",
    "template = \"\"\"This is a conversation between a human and a bot:\n",
    "\n",
    "{chat_history}\n",
    "\n",
    "Write a summary of the conversation for {input}:\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(input_variables=[\"input\", \"chat_history\"], template=template)\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\")\n",
    "summry_chain = LLMChain(\n",
    "    llm=OpenAI(),\n",
    "    prompt=prompt,\n",
    "    verbose=True,\n",
    "    memory=memory,  # <--- this is the only change\n",
    ")\n",
    "\n",
    "search = GoogleSearchAPIWrapper()\n",
    "tools = [\n",
    "    Tool(\n",
    "        name=\"Search\",\n",
    "        func=search.run,\n",
    "        description=\"useful for when you need to answer questions about current events\",\n",
    "    ),\n",
    "    Tool(\n",
    "        name=\"Summary\",\n",
    "        func=summry_chain.run,\n",
    "        description=\"useful for when you summarize a conversation. The input to this tool should be a string, representing who will read this summary.\",\n",
    "    ),\n",
    "]\n",
    "\n",
    "prefix = \"\"\"Have a conversation with a human, answering the following questions as best you can. You have access to the following tools:\"\"\"\n",
    "suffix = \"\"\"Begin!\"\n",
    "\n",
    "{chat_history}\n",
    "Question: {input}\n",
    "{agent_scratchpad}\"\"\"\n",
    "\n",
    "prompt = ZeroShotAgent.create_prompt(\n",
    "    tools,\n",
    "    prefix=prefix,\n",
    "    suffix=suffix,\n",
    "    input_variables=[\"input\", \"chat_history\", \"agent_scratchpad\"],\n",
    ")\n",
    "\n",
    "llm_chain = LLMChain(llm=OpenAI(temperature=0), prompt=prompt)\n",
    "agent = ZeroShotAgent(llm_chain=llm_chain, tools=tools, verbose=True)\n",
    "agent_chain = AgentExecutor.from_agent_and_tools(\n",
    "    agent=agent, tools=tools, verbose=True, memory=memory\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_chain.run(input=\"What is ChatGPT?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_chain.run(input=\"Who developed it?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_chain.run(\n",
    "    input=\"Thanks. Summarize the conversation, for my daughter 5 years old.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The final answer is not wrong, but we see the 3rd Human input is actually from the agent in the memory because the memory was modified by the summary tool.\n",
    "\n",
    "print(agent_chain.memory.buffer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.11 ('openai')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "382edab7741184ad6aa1b3bda453c7375fcc346d80c0b8f027407f5537ace097"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
